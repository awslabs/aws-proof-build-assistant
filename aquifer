#!/usr/bin/env python3
"""
aquifer tool:  helping developers get build information for source files they want to test.
"""

import argparse
import os
import json
import logging
import sys
import subprocess
import re

TOOL_NAME = "aquifer"
TOOL_PATH = os.path.dirname(__file__)
COMPILE_CMD_NAME = "compile_commands.json"

PROJECT_NAME = os.path.basename(os.getcwd())
OUT_DB_NAME = "Makefile.aquifer"
OUT_JSON_NAME = "internal_rep.json"

MAKE_FILEUT = "FILEUT"
MAKE_FUNCUT = "FUNCUT"
MAKE_INCLUDE = "INC"
MAKE_DEFINE = "DEFINES"
MAKE_DEPENDENCIES = "DEPENDENCIES"

CFLOW_OUT = "CFLOW_temp0"

def build(args):
    """ Generate a json build database from given compile commands.
    If not compile commands path given, generate compile commands.
    No return"""

    comp_cmds_path = args.compile_commands_json_path
    write_to_json = args.write_json
    save_path = args.save_path

    define_name = args.define_name
    if define_name:
        global MAKE_DEFINE
        MAKE_DEFINE = define_name

    include_name = args.include_name
    if include_name:
        global MAKE_INCLUDE
        MAKE_INCLUDE = include_name

    dependency_name = args.dependency_name
    if dependency_name:
        global MAKE_DEPENDENCIES
        MAKE_DEPENDENCIES = dependency_name

    dep_extension = args.dependency_extension

    # Load the generated compilation commands, if possible
    if not os.path.exists(comp_cmds_path):
        logging.error("Specified path does not point to an existing file: %s", comp_cmds_path)
        sys.exit(1)

    # get compilation commands
    out_db_path = OUT_DB_NAME
    internal_rep_path = OUT_JSON_NAME
    comp_cmds = None
    with open(comp_cmds_path, "r") as handle:
        comp_cmds = json.load(handle)

    # Extract relevant information
    internal_rep = {"files":{}}
    cflow_cmd = ["cflow"]

    for comp_cmd in comp_cmds:
        internal_file = {}
        # file name. TODO Only consider non-test files.
        file_path = str(comp_cmd['file'])
        # if file_path.endswith("test.c"):
        #     continue

        file_name = os.path.basename(file_path)
        internal_file["name"] = file_name
        # internal_file["name"] = file_name
        # file_dir = os.path.dirname(file_path)
        # internal_file["directory"] = file_dir
        if dep_extension:
            internal_file["alt_path"] = change_extension(file_path, dep_extension)
        else:
            internal_file["alt_path"] = None

        #COMMAND
        command_split = comp_cmd['command'].split()
        command_include_dirs = []
        command_defines = []
        for cmd_tup in enumerate(command_split):
            cmd_ind = cmd_tup[0]
            next_arg = "" if cmd_ind == len(command_split)-1 else command_split[cmd_ind+1]
            include = get_flag_arg("-I", command_split[cmd_ind], next_arg)
            if include:
                command_include_dirs.append(include)
            # include = get_flag_arg("-isystem", command_split[cmd_ind], next_arg)
            # if include:
            #     command_include_dirs.append(include)
            define = get_flag_arg("-D", command_split[cmd_ind], next_arg)
            if define:
                command_defines.append(define)

        # CFLOW prep
        cflow_cmd.append(file_path)
        header = find_header(file_path)
        if header:
            cflow_cmd.append(header)

        # fill in intrernal representation
        internal_file[MAKE_INCLUDE] = command_include_dirs
        internal_file[MAKE_DEFINE] = command_defines
        internal_file["functions"] = {}

        # collect makefile information
        if file_name in internal_rep["files"]:
            path1 = file_path
            path2 = internal_rep["files"][file_name]["abspath"]
            logging.warning("Clashing file name: %s  <>  %s", path1, path2)
        else:
            internal_rep["files"][file_path] = internal_file

    # HANDLING DEPENDENCIES
    # run CFLOW, and output to file
    i = 0
    while True:
        global CFLOW_OUT
        CFLOW_OUT = CFLOW_OUT[:-1] + str(i)
        i += 1
        if not os.path.exists(CFLOW_OUT):
            break

    cflow_cmd.extend(["-A", "--no-main", "-o"+CFLOW_OUT, "--brief"])
    subprocess.call(cflow_cmd)

    # parse CFLOW output
    parse_cflow(internal_rep)

    # Write to files
    if write_to_json:
        write_internal_representation(internal_rep, write_to_json)
    else:
        write_internal_representation(internal_rep, internal_rep_path)

    if save_path:
        write_makefile(internal_rep, save_path)
    else:
        write_makefile(internal_rep, out_db_path)


def parse_cflow(rep):
    """parse cflow output file. integrate it into json internal representation"""

    with open(CFLOW_OUT, "r") as cflow:

        current_at_level = []
        for cur_line in cflow.readlines():

            # get depth of current line
            leading_spaces = len(cur_line) - len(cur_line.lstrip(" "))
            cur_depth = int(leading_spaces/4)
            if leading_spaces%4:
                logging.warning("Line has %d leading spaces: %s", leading_spaces, cur_line[:-1])

            #add function to internal rep
            regex = r"(?P<fct>\w+)\(\)( <.+ at (?P<file>.+):\d+>( (?P<rec>\(R\)))?:)?( \[see (?P<ref>\d+)\])?"
            match = re.search(regex, cur_line)
            if not match:
                logging.warning("Regex did not match for \"%s\"", cur_line)
                break

            parsed_define = match.groupdict()
            cf_func = parsed_define["fct"]
            cf_file = parsed_define["file"]
            cf_ref = parsed_define["ref"]
            if cf_file and not cf_ref:
                if cf_file in rep["files"]:
                    if cf_func in rep["files"][cf_file]["functions"]:
                        logging.warning("duplicate entry for %s in %s", cf_func, cf_file)
                    rep["files"][cf_file]["functions"][cf_func] = {}
                else:
                    logging.warning("%s not found in internal representation", cf_file)

            #handle function callings
            cur_node = (cf_func, cf_file)

            if cur_depth < len(current_at_level)-1:
                current_at_level = current_at_level[:cur_depth+1]
                current_at_level[cur_depth] = cur_node
            if cur_depth == len(current_at_level)-1:
                current_at_level[cur_depth] = cur_node
            if cur_depth == len(current_at_level):
                current_at_level.append(cur_node)
            if cur_depth > len(current_at_level):
                logging.warning("jump in depth at line NOT AVAILABLE", )
            if cur_depth != 0:
                #add to 1 depth less
                parent_depth = cur_depth - 1
                parent_func = current_at_level[parent_depth][0]
                parent_file = current_at_level[parent_depth][1]
                if not parent_file in rep["files"]:
                    logging.warning("Parent file %s of calling function %s of called function %s is not found in internal rep.",
                                    parent_file, parent_func, cf_func)
                else:
                    rep["files"][parent_file]["functions"][parent_func][cf_func] = cf_file

    os.remove(CFLOW_OUT)

def find_header(file_path):
    """If a file has a header with the corresponding name, return it"""
    if not file_path.endswith(".c"):
        return None

    header_path = file_path[:-2] + ".h"
    if not os.path.exists(header_path):
        # logging.warning("No header file found for %s", file_path)
        return None
    return header_path


def change_extension(path, new_ext):
    """change the extension of a file given it's path"""
    name, _ = os.path.splitext(path)
    return name + "." + new_ext


def write_internal_representation(rep, path):
    """ output a file continaing the json internal representation used in the tool """
    outjson = json.dumps(rep, indent=4)
    with open(path, "w") as handle:
        print(outjson, file=handle)
    print("-- Saved the internal representation at: {}".format(os.path.abspath(path)))


def write_makefile(rep, path):
    """ write the Makefile """
    all_files = rep["files"]
    out_lines = []
    for file in all_files:
        dep = file
        if all_files[file]["alt_path"]:
            dep = all_files[file]["alt_path"]
        out_lines.append("ifneq (,$(findstring %s, %s))" % (dep, make_value(MAKE_DEPENDENCIES)))

        #iterate through includes
        for inc in all_files[file][MAKE_INCLUDE]:
            out_lines.extend(add_if_not_there(inc, MAKE_INCLUDE))

        #iterate through defines
        for define in all_files[file][MAKE_DEFINE]:
            out_lines.extend(add_if_not_there(define, MAKE_DEFINE))

        out_lines.append("endif\n")

    # Write to output file
    with open(path, "w") as output:
        print("\n".join(out_lines), file=output)
    print("-- Created aquifer Makefile at {}".format(os.path.abspath(path)))


def add_if_not_there(file, tag):
    """ add conditional append of Make variable to list of test lines """
    lines = []
    lines.append("  ifeq (,$(findstring %s, %s))" % (file, make_value(tag)))
    lines.append("    %s" % add_to_var(tag, file))
    lines.append("  endif")
    return lines


def make_value(var):
    """ return MAKE syntax for accessing a variable value """
    return "$(" + str(var) + ")"


def add_to_var(var, term):
    """ return correct MAKE syntax for adding a value to a variable. """
    return "%s += %s" % (var, term)


def get_flag_arg(flag, arg, next_arg):
    """ if string corresponds to correct flag, return corresponding argument. """
    if len(arg) < len(flag):
        return None
    if len(arg) == len(flag) and arg == flag:
        return arg + " " + next_arg
    if len(arg) > len(flag) and arg[:len(flag)] == flag:
        return arg


def print_file(args):
    """ Print build information for a selected file. No return. """

    path_to_file = args.file_path
    print("print is not yet implemented - file {}".format(path_to_file))


def render(args):
    """ Generate a web interface containing build data for all fioles. No return. """

    print("render is not yet implemented")


def parse_args():
    """parse arguments"""
    parser = argparse.ArgumentParser(description=__doc__)
    subparser = parser.add_subparsers(help="Available commands for {}".format(TOOL_NAME))

    # build command
    parser_build = subparser.add_parser('build', help="Generate a build database \
        for the current project.")
    parser_build.add_argument("compile_commands_json_path",
                              help="path to compile_commands json file.")
    parser_build.add_argument("-sp", "--save-path",
                              help="file path where the output Makefile will be saved")
    parser_build.add_argument("-wj", "--write-json",
                              help="output a file containing a json internal \
                              representation of the stored information. \
                              Possible to add save path")
    parser_build.add_argument("-def", "--define_name",
                              help="label for defines used in the Makefile")
    parser_build.add_argument("-inc", "--include_name",
                              help="label for includes used in the Makefile")
    parser_build.add_argument("-dep", "--dependency_name",
                              help="label for dependencies used in the Makefile")
    parser_build.add_argument("-dx", "--dependency_extension",
                              help="alternate extension for dependecies")
    parser_build.set_defaults(func=build)

    # print command
    parser_print = subparser.add_parser('print', help="Print build information \
        for a selected file.")
    parser_print.add_argument("file_path", default="",
                              help="path to file to output info for.")
    parser_print.set_defaults(func=print_file)

    # render command
    parser_render = subparser.add_parser('render', help="Generate a web interface \
        containing {} data.".format(TOOL_NAME))
    parser_render.set_defaults(func=render)

    # parse and run
    return parser.parse_args()


def main():
    """ Main function """

    logging.basicConfig(filename=os.path.join(os.path.dirname(__file__), "aquifer.log"),
                        level=logging.DEBUG)

    arguments = parse_args()
    arguments.func(arguments)
    print()


if __name__ == "__main__":
    main()
